{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numba\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import gzip\n",
    "import urllib.request\n",
    "from string import punctuation\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_word_counts(word_counts):\n",
    "    df = pd.DataFrame(word_counts, columns=[\"word\", \"count\"])\n",
    "\n",
    "    total_words = df[\"count\"].sum()\n",
    "    unique_words = len(word_counts)\n",
    "    print(\"Total words: %d\"%total_words)\n",
    "    print(\"Total words: %d\"%unique_words)\n",
    "    print(\"$\\\\rho_{est}$: %.3f\"%(unique_words/total_words))\n",
    "\n",
    "    for i in range(1,3+1):\n",
    "        count = df[df[\"count\"] == i].shape\n",
    "        print(\"There were %5d words used %d times each\"%(count[0], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses_url = \"http://www.uvm.edu/pdodds/teaching/courses/2020-08UVM-300/docs/ulysses.txt\"\n",
    "def generate_word_counts_ulysses():\n",
    "    print(\"Running for Ulysses...\")\n",
    "    with urllib.request.urlopen(ulysses_url) as f:\n",
    "        word_counts =  [tuple(l.split()) for l in f.read().decode(\"utf-8\").split(\"\\n\") if l != \"\"]\n",
    "    word_counts = [(a[:-1], int(b)) for (a,b) in word_counts]\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for Ulysses\n",
      "Total words: 264706\n",
      "Total words: 31398\n",
      "$\\rho_{est}$: 0.119\n",
      "There were 17738 words used 1 times each\n",
      "There were  4887 words used 2 times each\n",
      "There were  2241 words used 3 times each\n"
     ]
    }
   ],
   "source": [
    "analyze_word_counts(generate_word_counts_ulysses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_and_prejudice_url = \"https://www.gutenberg.org/files/1342/1342-0.txt\"\n",
    "def generate_word_counts_pride_prejudice():\n",
    "    print(\"Running for Pride and Prejudice...\")\n",
    "    with urllib.request.urlopen(pride_and_prejudice_url) as f:\n",
    "        raw = f.read().decode(\"utf-8\")\n",
    "    \n",
    "    exclude = set(punctuation) \n",
    "\n",
    "    raw_trimmed = raw.split(\"\\r\\n\")[35:-368] # remove boilerplate content\n",
    "    raw_joined = \" \".join(data_trimmed)\n",
    "    list_letters_noPunct =  [ char for char in raw_joined if char not in exclude ]\n",
    "    text_noPunct = \"\".join(list_letters_noPunct)\n",
    "    list_words = text_noPunct.strip().split()\n",
    "    words_counter = Counter(list_words)\n",
    "    \n",
    "    return(list(words_counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for Pride and Prejudice\n",
      "Total words: 121662\n",
      "Total words: 8206\n",
      "$\\rho_{est}$: 0.067\n",
      "There were  3668 words used 1 times each\n",
      "There were  1218 words used 2 times each\n",
      "There were   689 words used 3 times each\n"
     ]
    }
   ],
   "source": [
    "analyze_word_counts(generate_word_counts_pride_prejudice())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_comte_urls = [\"https://www.gutenberg.org/ebooks/17989.txt.utf-8\", # volume 1 - 4\n",
    "                \"https://www.gutenberg.org/ebooks/17990.txt.utf-8\",\n",
    "                \"https://www.gutenberg.org/ebooks/17991.txt.utf-8\",\n",
    "                \"https://www.gutenberg.org/ebooks/17992.txt.utf-8\"]\n",
    "\n",
    "def generate_word_counts_le_comte():\n",
    "    print(\"Running for Le comte...\")\n",
    "    raws = [urllib.request.urlopen(url).read().decode(\"utf-8\") for url in le_comte_urls]\n",
    "    raws_trimmed = [raw.split(\"\\r\\n\")[25: -368] for raw in raws] # remove boilerplate code\n",
    "    raws_joined = []\n",
    "    for raw in raws_trimmed:\n",
    "        raws_joined += raw\n",
    "    list_letters_noPunct =  [ char for char in raws_joined if char not in exclude ]\n",
    "    text_noPunct = \"\".join(list_letters_noPunct)\n",
    "    list_words = text_noPunct.strip().split()\n",
    "    words_counter = Counter(list_words)\n",
    "    \n",
    "    return(list(words_counter.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for Le comte...\n",
      "Total words: 420611\n",
      "Total words: 76625\n",
      "$\\rho_{est}$: 0.182\n",
      "There were 57981 words used 1 times each\n",
      "There were  7287 words used 2 times each\n",
      "There were  3113 words used 3 times each\n"
     ]
    }
   ],
   "source": [
    "analyze_word_counts(generate_word_counts_le_comte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
